{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45c85f94c95b5ccf",
   "metadata": {},
   "source": [
    "# Training RNA2seg on Zarr-Saved SpatialData  \n",
    "\n",
    "This notebook demonstrates how to train RNA2seg on spatial transcriptomics data stored in a Zarr file. The process consists of four main steps:  \n",
    "\n",
    "1. **Patch Creation** – Extract patches of a reasonable size to process efficiently (saved in the Zarr file).  \n",
    "2. **Filtered Target Generation** – Create a curated segmentation mask from a teacher model for RNA2seg training (saved in the Zarr file).  \n",
    "3. **Model Training** – Train RNA2seg using the generated patches and filtered segmentation.  \n",
    "4. **Apply to the whole dataset** – Use the notebook `apply_model_on_zarr.ipynb` to apply the trained model to the entire dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094f120a",
   "metadata": {},
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf4aca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c645b82d3b2173fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T14:44:29.532122Z",
     "start_time": "2025-02-06T14:44:22.498902Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import spatialdata as sd\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "\n",
    "from rna2seg.dataset_zarr import (\n",
    "    RNA2segDataset, custom_collate_fn, compute_consistent_cell\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd139779-deee-4a88-b02a-89628a171fcf",
   "metadata": {},
   "source": [
    "### Set your own path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecc8cc5c-6189-4666-927f-b70cb6e3563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## path to spatial data\n",
    "merfish_zarr_path = \"/media/tom/Transcend/open_merfish/test_spatial_data/from_cluster/test_mouse_ileum.zarr\"\n",
    "\n",
    "## \n",
    "path_save_model  = \"/media/tom/Transcend/open_merfish/test_spatial_data/from_cluster/modelm\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d958b7bbf928bf",
   "metadata": {},
   "source": [
    "## Step 1: Create training patches from Zarr files\n",
    "\n",
    "In this step, the dataset (image + transcripts) is divided into patches of size `patch_width × patch_width` with an overlap of `patch_overlap`. This allows processing images of a manageable size while preserving spatial continuity.  \n",
    "\n",
    "**Process** \n",
    "- The dataset, stored in Zarr format, is loaded.  \n",
    "- Patches coordinates are saved as a `Shape` in the zarr: `sopa_patches_rna2seg_[patch_width]_[patch_overlap]`. \n",
    "- A `.rna2seg` directory is created to store the transcript data corresponding to each patch.  \n",
    "- The transcript information for each patch is saved in CSV format for further processing.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60be0f9817553592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T13:28:17.140897Z",
     "start_time": "2025-01-15T13:28:17.023449Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36;20m[INFO] (sopa.patches._patches)\u001b[0m Added 64 patche(s) to sdata['sopa_patches_rna2seg_1200_50']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 16.20 ss\n",
      "[########################################] | 100% Completed | 12.26 s\n",
      "SpatialData object, with associated Zarr store: /media/tom/Transcend/open_merfish/test_spatial_data/from_cluster/test_mouse_ileum.zarr\n",
      "├── Images\n",
      "│     └── 'staining_z3': DataTree[cyx] (5, 9000, 9000), (5, 4500, 4500), (5, 2250, 2250), (5, 1125, 1125), (5, 562, 562)\n",
      "├── Points\n",
      "│     └── 'transcripts': DataFrame with shape: (<Delayed>, 9) (2D points)\n",
      "└── Shapes\n",
      "      ├── 'Cellbound1': GeoDataFrame shape: (3258, 1) (2D shapes)\n",
      "      ├── 'DAPI': GeoDataFrame shape: (2377, 1) (2D shapes)\n",
      "      ├── 'sopa_patches_rna2seg_1200_50': GeoDataFrame shape: (64, 3) (2D shapes)\n",
      "      ├── 'sopa_patches_rna2seg_1200_150': GeoDataFrame shape: (81, 3) (2D shapes)\n",
      "      └── 'test_rnas2eg': GeoDataFrame shape: (3011, 1) (2D shapes)\n",
      "with coordinate systems:\n",
      "    ▸ 'global', with elements:\n",
      "        test_rnas2eg (Shapes)\n",
      "    ▸ 'microns', with elements:\n",
      "        staining_z3 (Images), transcripts (Points), Cellbound1 (Shapes), DAPI (Shapes), sopa_patches_rna2seg_1200_50 (Shapes), sopa_patches_rna2seg_1200_150 (Shapes)\n"
     ]
    }
   ],
   "source": [
    "from rna2seg.dataset_zarr import create_patch_rna2seg\n",
    "\n",
    "### load sdata and set path parameters \n",
    "sdata = sd.read_zarr(merfish_zarr_path)\n",
    "image_key = \"staining_z3\"\n",
    "patch_width = 1200\n",
    "patch_overlap = 50\n",
    "points_key = \"transcripts\"\n",
    "min_transcripts_per_patch = 0\n",
    "folder_patch_rna2seg = Path(merfish_zarr_path) / f\".rna2seg_{patch_width}_{patch_overlap}\"\n",
    "\n",
    "### create patch in the sdata and precompute transcipt.csv for each patch with sopa\n",
    "create_patch_rna2seg(sdata,\n",
    "                    image_key=image_key,\n",
    "                    points_key=points_key,\n",
    "                    patch_width=patch_width,\n",
    "                    patch_overlap=patch_overlap,\n",
    "                    min_transcripts_per_patch=min_transcripts_per_patch,\n",
    "                    folder_patch_rna2seg = folder_patch_rna2seg,\n",
    "                    overwrite = True)\n",
    "print(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f5cac439b7149",
   "metadata": {},
   "source": [
    "## Step 2: Create a Consistent Target for Training RNA2seg\n",
    "\n",
    "**Input:** Spatial data with potentially erroneous nucleus and cell segmentations.  \n",
    "**Output:** Curated cell and nucleus segmentations for training RNA2seg. Saved in the zarr.\n",
    "\n",
    "This step refines two segmentations stored in the Zarr file: **cell segmentation** (`key_shape_cell_seg`) and **nuclei segmentation** (`key_nuclei_segmentation`).  \n",
    "The goal is to generate a **teacher segmentation** by filtering out inconsistencies between cells and nuclei.  \n",
    "\n",
    "**Process** \n",
    "1. Load the segmentations (`Cellbound1` and `DAPI`) from the Zarr file.  \n",
    "2. Apply a **consistency check** to remove unreliable segmentations:  \n",
    "   - **Consistent cell segmentation** → `Cellbound1_consistent`  \n",
    "   - **Consistent nuclei segmentation** → `DAPI_consistent`  \n",
    "3. Save the refined segmentations back into the Zarr file.  \n",
    "\n",
    "This ensures high-quality annotations for training or fine-tuning RNA2seg.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3508e0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving conflicts: 7688it [00:00, 10603.65it/s]\n"
     ]
    }
   ],
   "source": [
    "key_cell_segmentation = \"Cellbound1\"\n",
    "key_nuclei_segmentation=\"DAPI\"\n",
    "# to name for future shape that will be created in the sdata\n",
    "key_cell_consistent = \"Cellbound1_consistent\"\n",
    "key_nucleus_consistent = \"DAPI_consistent\"\n",
    "\n",
    "sdata = sd.read_zarr(merfish_zarr_path)\n",
    "\n",
    "sdata, _ = compute_consistent_cell(\n",
    "    sdata=sdata,\n",
    "    key_shape_nuclei_seg=key_nuclei_segmentation,\n",
    "    key_shape_cell_seg=key_cell_segmentation,\n",
    "    key_cell_consistent=key_cell_consistent,\n",
    "    key_nuclei_consistent=key_nucleus_consistent,\n",
    "    image_key=\"staining_z3\",\n",
    "    threshold_intersection_contain=0.95,\n",
    "    threshold_intersection_intersect= 1,\n",
    "    accepted_nb_nuclei_per_cell=None,\n",
    "    max_cell_nb_intersecting_nuclei=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9ebdb1",
   "metadata": {},
   "source": [
    "## Step 3: Training RNA2seg\n",
    "\n",
    "Now, we will train RNA2seg using the target segmentation created in Step 2.  \n",
    "\n",
    "### Initialize a RNA2segDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68afe78c9f9e67da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'vmunet'\n",
      "VMUnet not loaded\n",
      "100%|██████████| 64/64 [00:00<00:00, 83.27it/s]\n",
      "Number of valid patches: 48\n",
      "100%|██████████| 64/64 [00:00<00:00, 80.87it/s]\n",
      "compute density threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:07<00:00,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute density threshold: 7.559024s\n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from rna2seg.models import RNA2seg\n",
    "\n",
    "transform_resize  = A.Compose([\n",
    " A.Resize(width=512, height=512, interpolation=cv2.INTER_NEAREST),\n",
    "])\n",
    "\n",
    "dataset = RNA2segDataset(\n",
    "   sdata=sdata,\n",
    "   channels_dapi= [\"DAPI\"],\n",
    "   channels_cellbound=[\"Cellbound1\"],\n",
    "   shape_patch_key=f\"sopa_patches_rna2seg_{patch_width}_{patch_overlap}\", # Created at step 1\n",
    "   key_cell_consistent=key_cell_consistent, # Created at step 2\n",
    "   key_nucleus_consistent=key_nucleus_consistent, # Created at step 2\n",
    "   key_nuclei_segmentation=key_nuclei_segmentation,\n",
    "   gene_column=\"gene\",\n",
    "   density_threshold = None,\n",
    "   kernel_size_background_density = 10 ,\n",
    "   kernel_size_rna2img = 0.5,\n",
    "   max_filter_size_rna2img = 2,\n",
    "   transform_resize = transform_resize,\n",
    "   training_mode = True,\n",
    "   patch_dir = folder_patch_rna2seg,\n",
    "   patch_width=1200,\n",
    "   patch_overlap=50,\n",
    "   use_cache = True, \n",
    ")\n",
    "\n",
    "print((len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "238e86c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['img_cellbound', 'dapi', 'rna_img', 'mask_flow', 'mask_gradient', 'idx', 'patch_index', 'bounds', 'segmentation_nuclei'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b3cfdf",
   "metadata": {},
   "source": [
    "### Train / Validataion split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f02bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "train_indices, val_indices = train_test_split(\n",
    "    range(len(dataset)), test_size=0.1, shuffle=True, random_state=42\n",
    ")\n",
    "train_sampler = SubsetRandomSampler(train_indices) \n",
    "valid_sampler = SubsetRandomSampler(val_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec226eab",
   "metadata": {},
   "source": [
    "### Initialize Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "441fd505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(training_loader) 22\n",
      "len(training_loader) 3\n"
     ]
    }
   ],
   "source": [
    "training_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                              batch_size=2,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers = 0,\n",
    "                                              sampler=train_sampler,\n",
    "                                              collate_fn = custom_collate_fn,\n",
    "                                              )\n",
    "\n",
    "print( f\"len(training_loader) {len(training_loader)}\")\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                                batch_size=2,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers = 0,\n",
    "                                                sampler=valid_sampler,\n",
    "                                                collate_fn = custom_collate_fn,\n",
    "                                                )\n",
    "\n",
    "print( f\"len(training_loader) {len(validation_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500719ae4a3014d6",
   "metadata": {},
   "source": [
    "### Initilize RNA2seg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ca6ce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5da486ed8094a36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initiaisation of CPnet\n",
      "Initiaisation of ChannelInvariantNet\n"
     ]
    }
   ],
   "source": [
    "rna2seg = RNA2seg(\n",
    "    device,\n",
    "    net='unet',\n",
    "    flow_threshold = 0.9,\n",
    "    cellbound_flow_threshold = 0.4,\n",
    "    pretrained_model = None,\n",
    ")\n",
    "rna2seg = rna2seg.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(rna2seg.parameters(), lr=0.001, weight_decay=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c96e56",
   "metadata": {},
   "source": [
    "### Training RNA2seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "646fc91640fc8f93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A  validation loss: 13.405842463175455, ?it/s]\n",
      "best_val_loss: 13.405842463175455\n",
      "\n",
      "\u001b[Aining:   5%|▍         | 1/22 [00:12<04:18, 12.31s/it]\n",
      "\u001b[Aining:   9%|▉         | 2/22 [00:18<02:53,  8.69s/it]\n",
      "\u001b[Aining:  14%|█▎        | 3/22 [00:24<02:22,  7.50s/it]\n",
      "\u001b[Aining:  18%|█▊        | 4/22 [00:30<02:05,  6.99s/it]\n",
      "\u001b[Aining:  23%|██▎       | 5/22 [00:36<01:52,  6.62s/it]\n",
      "\u001b[Aining:  27%|██▋       | 6/22 [00:43<01:44,  6.55s/it]\n",
      "\u001b[A  validation loss: 12.7456032435099281:33,  6.25s/it]\n",
      "best_val_loss: 12.745603243509928\n",
      "\n",
      "\u001b[Aining:  36%|███▋      | 8/22 [00:59<01:48,  7.74s/it]\n",
      "\u001b[Aining:  41%|████      | 9/22 [01:05<01:31,  7.03s/it]\n",
      "\u001b[Aining:  45%|████▌     | 10/22 [01:10<01:18,  6.56s/it]\n",
      "\u001b[Aining:  50%|█████     | 11/22 [01:16<01:09,  6.31s/it]\n",
      "\u001b[Aining:  55%|█████▍    | 12/22 [01:22<01:02,  6.23s/it]\n",
      "\u001b[Aining:  59%|█████▉    | 13/22 [01:28<00:55,  6.13s/it]\n",
      "\u001b[A  validation loss: 12.13439718882242800:49,  6.15s/it]\n",
      "best_val_loss: 12.134397188822428\n",
      "\n",
      "\u001b[Aining:  68%|██████▊   | 15/22 [01:46<00:55,  7.97s/it]\n",
      "\u001b[Aining:  73%|███████▎  | 16/22 [01:52<00:44,  7.38s/it]\n",
      "\u001b[Aining:  77%|███████▋  | 17/22 [01:58<00:34,  6.84s/it]\n",
      "\u001b[Aining:  82%|████████▏ | 18/22 [02:04<00:26,  6.60s/it]\n",
      "\u001b[Aining:  86%|████████▋ | 19/22 [02:10<00:19,  6.36s/it]\n",
      "\u001b[Aining:  91%|█████████ | 20/22 [02:16<00:12,  6.47s/it]\n",
      "\u001b[A  validation loss: 11.69545237223307200:06,  6.31s/it]\n",
      "best_val_loss: 11.695452372233072\n",
      "\n",
      "training: 100%|██████████| 22/22 [02:30<00:00,  6.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [02:30<05:01, 150.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A  validation loss: 11.542235692342123, ?it/s]\n",
      "best_val_loss: 11.542235692342123\n",
      "\n",
      "\u001b[Aining:   5%|▍         | 1/22 [00:10<03:47, 10.83s/it]\n",
      "\u001b[Aining:   9%|▉         | 2/22 [00:16<02:40,  8.03s/it]\n",
      "\u001b[Aining:  14%|█▎        | 3/22 [00:22<02:11,  6.90s/it]\n",
      "\u001b[Aining:  18%|█▊        | 4/22 [00:28<01:54,  6.37s/it]\n",
      "\u001b[Aining:  23%|██▎       | 5/22 [00:33<01:43,  6.09s/it]\n",
      "\u001b[Aining:  27%|██▋       | 6/22 [00:39<01:38,  6.15s/it]\n",
      "\u001b[A  validation loss: 10.6438512802124021:28,  5.88s/it]\n",
      "best_val_loss: 10.643851280212402\n",
      "\n",
      "\u001b[Aining:  36%|███▋      | 8/22 [00:55<01:43,  7.36s/it]\n",
      "\u001b[Aining:  41%|████      | 9/22 [01:01<01:28,  6.77s/it]\n",
      "\u001b[Aining:  45%|████▌     | 10/22 [01:06<01:16,  6.35s/it]\n",
      "\u001b[Aining:  50%|█████     | 11/22 [01:12<01:07,  6.12s/it]\n",
      "\u001b[Aining:  55%|█████▍    | 12/22 [01:17<00:59,  5.94s/it]\n",
      "\u001b[Aining:  59%|█████▉    | 13/22 [01:23<00:52,  5.87s/it]\n",
      "\u001b[A  validation loss: 10.98107210795084600:46,  5.76s/it]\n",
      "\n",
      "\u001b[Aining:  68%|██████▊   | 15/22 [01:39<00:49,  7.06s/it]\n",
      "\u001b[Aining:  73%|███████▎  | 16/22 [01:44<00:39,  6.56s/it]\n",
      "\u001b[Aining:  77%|███████▋  | 17/22 [01:50<00:31,  6.27s/it]\n",
      "\u001b[Aining:  82%|████████▏ | 18/22 [01:55<00:24,  6.06s/it]\n",
      "\u001b[Aining:  86%|████████▋ | 19/22 [02:00<00:17,  5.86s/it]\n",
      "\u001b[Aining:  91%|█████████ | 20/22 [02:06<00:11,  5.76s/it]\n",
      "\u001b[A  validation loss: 10.35590712229410700:05,  5.73s/it]\n",
      "best_val_loss: 10.355907122294107\n",
      "\n",
      "training: 100%|██████████| 22/22 [02:19<00:00,  6.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [04:50<02:24, 144.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A  validation loss: 10.06841786702474?, ?it/s]\n",
      "best_val_loss: 10.06841786702474\n",
      "\n",
      "\u001b[Aining:   5%|▍         | 1/22 [00:11<03:55, 11.21s/it]\n",
      "\u001b[Aining:   9%|▉         | 2/22 [00:16<02:39,  7.99s/it]\n",
      "\u001b[Aining:  14%|█▎        | 3/22 [00:22<02:12,  6.97s/it]\n",
      "\u001b[Aining:  18%|█▊        | 4/22 [00:28<01:54,  6.34s/it]\n",
      "\u001b[Aining:  23%|██▎       | 5/22 [00:33<01:44,  6.14s/it]\n",
      "\u001b[Aining:  27%|██▋       | 6/22 [00:39<01:35,  5.96s/it]\n",
      "\u001b[A  validation loss: 9.18920675913492801:30,  6.07s/it]\n",
      "best_val_loss: 9.189206759134928\n",
      "\n",
      "\u001b[Aining:  36%|███▋      | 8/22 [00:56<01:44,  7.45s/it]\n",
      "\u001b[Aining:  41%|████      | 9/22 [01:01<01:28,  6.81s/it]\n",
      "\u001b[Aining:  45%|████▌     | 10/22 [01:07<01:17,  6.42s/it]\n",
      "\u001b[Aining:  50%|█████     | 11/22 [01:12<01:07,  6.16s/it]\n",
      "\u001b[Aining:  55%|█████▍    | 12/22 [01:19<01:02,  6.23s/it]\n",
      "\u001b[Aining:  59%|█████▉    | 13/22 [01:25<00:55,  6.18s/it]\n",
      "\u001b[A  validation loss: 9.122661113739014<00:48,  6.08s/it]\n",
      "best_val_loss: 9.122661113739014\n",
      "\n",
      "\u001b[Aining:  68%|██████▊   | 15/22 [01:41<00:52,  7.54s/it]\n",
      "\u001b[Aining:  73%|███████▎  | 16/22 [01:47<00:41,  6.95s/it]\n",
      "\u001b[Aining:  77%|███████▋  | 17/22 [01:54<00:34,  6.91s/it]\n",
      "\u001b[Aining:  82%|████████▏ | 18/22 [02:00<00:26,  6.64s/it]\n",
      "\u001b[Aining:  86%|████████▋ | 19/22 [02:06<00:19,  6.36s/it]\n",
      "\u001b[Aining:  91%|█████████ | 20/22 [02:11<00:12,  6.09s/it]\n",
      "\u001b[A  validation loss: 7.945613702138265<00:05,  5.94s/it]\n",
      "best_val_loss: 7.945613702138265\n",
      "\n",
      "training: 100%|██████████| 22/22 [02:24<00:00,  6.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [07:15<00:00, 145.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from rna2seg.train import train_one_epoch\n",
    "\n",
    "best_val_loss = np.inf\n",
    "\n",
    "\n",
    "for epoch_index in tqdm(range(3)):\n",
    "\n",
    "    train_one_epoch(\n",
    "        device=device,\n",
    "        epoch_index=epoch_index,\n",
    "        rna2seg=rna2seg,\n",
    "        training_loader=training_loader,\n",
    "        optimizer=optimizer,\n",
    "        print_loss_every = int(len(training_loader) /3),\n",
    "        tb_writer= None,\n",
    "        validation_loader=validation_loader,\n",
    "        path_save_model=path_save_model,\n",
    "        cellbound_prob= 0.8,\n",
    "        best_val_loss=best_val_loss\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
