{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45c85f94c95b5ccf",
   "metadata": {},
   "source": [
    "# Training RNA2seg on Zarr-Saved SpatialData  \n",
    "\n",
    "This notebook demonstrates how to train RNA2seg on spatial transcriptomics data stored in a Zarr file. The process consists of four main steps:  \n",
    "\n",
    "1. **Patch Creation** – Extract patches of a reasonable size to process efficiently (saved in the Zarr file).  \n",
    "2. **Filtered Target Generation** – Create a curated segmentation mask from a teacher model for RNA2seg training (saved in the Zarr file).  \n",
    "3. **Model Training** – Train RNA2seg using the generated patches and filtered segmentation.  \n",
    "4. **Apply to the whole dataset** – Use the notebook `apply_model_on_zarr.ipynb` to apply the trained model to the entire dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094f120a",
   "metadata": {},
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf4aca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c645b82d3b2173fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T14:44:29.532122Z",
     "start_time": "2025-02-06T14:44:22.498902Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import spatialdata as sd\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "\n",
    "from rna2seg.dataset_zarr import (\n",
    "    RNA2segDataset, custom_collate_fn, compute_consistent_cell\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d958b7bbf928bf",
   "metadata": {},
   "source": [
    "## Step 1: Create training patches from Zarr files\n",
    "\n",
    "In this step, the dataset (image + transcripts) is divided into patches of size `patch_width × patch_width` with an overlap of `patch_overlap`. This allows processing images of a manageable size while preserving spatial continuity.  \n",
    "\n",
    "**Process** \n",
    "- The dataset, stored in Zarr format, is loaded.  \n",
    "- Patches coordinates are saved as a `Shape` in the zarr: `sopa_patches_rna2seg_[patch_width]_[patch_overlap]`. \n",
    "- A `.rna2seg` directory is created to store the transcript data corresponding to each patch.  \n",
    "- The transcript information for each patch is saved in CSV format for further processing.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60be0f9817553592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T13:28:17.140897Z",
     "start_time": "2025-01-15T13:28:17.023449Z"
    }
   },
   "outputs": [],
   "source": [
    "from rna2seg.dataset_zarr import create_patch_rnaseg\n",
    "\n",
    "### load sdata and set path parameters \n",
    "merfish_zarr_path = \"/Users/alice/Documents/data/Cell_Segmentation/test_mouse_ileum.zarr\"\n",
    "sdata = sd.read_zarr(merfish_zarr_path)\n",
    "image_key = \"staining_z3\"\n",
    "patch_width = 1200\n",
    "patch_overlap = 50\n",
    "points_key = \"transcripts\"\n",
    "min_transcripts_per_patch = 0\n",
    "folder_patch_rna2seg = Path(merfish_zarr_path) / \".rna2seg\"\n",
    "\n",
    "### create patch in the sdata and precompute transcipt.csv for each patch with sopa\n",
    "create_patch_rnaseg(sdata,\n",
    "                    image_key=image_key,\n",
    "                    points_key=points_key,\n",
    "                    patch_width=patch_width,\n",
    "                    patch_overlap=patch_overlap,\n",
    "                    min_transcripts_per_patch=min_transcripts_per_patch,\n",
    "                    folder_patch_rna2seg = folder_patch_rna2seg,\n",
    "                    overwrite = True)\n",
    "print(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f5cac439b7149",
   "metadata": {},
   "source": [
    "## Step 2: Create a Consistent Target for Training RNAseg\n",
    "\n",
    "**Input:** Spatial data with potentially erroneous nucleus and cell segmentations.  \n",
    "**Output:** Curated cell and nucleus segmentations for training RNAseg. Saved in the zarr.\n",
    "\n",
    "This step refines two segmentations stored in the Zarr file: **cell segmentation** (`key_shape_cell_seg`) and **nuclei segmentation** (`key_nuclei_segmentation`).  \n",
    "The goal is to generate a **teacher segmentation** by filtering out inconsistencies between cells and nuclei.  \n",
    "\n",
    "**Process** \n",
    "1. Load the segmentations (`Cellbound1` and `DAPI`) from the Zarr file.  \n",
    "2. Apply a **consistency check** to remove unreliable segmentations:  \n",
    "   - **Consistent cell segmentation** → `Cellbound1_consistent`  \n",
    "   - **Consistent nuclei segmentation** → `DAPI_consistent`  \n",
    "3. Save the refined segmentations back into the Zarr file.  \n",
    "\n",
    "This ensures high-quality annotations for training or fine-tuning RNAseg.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3508e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cell_segmentation = \"Cellbound1\"\n",
    "key_nuclei_segmentation=\"DAPI\"\n",
    "# to name for future shape that will be created in the sdata\n",
    "key_cell_consistent = \"Cellbound1_consistent\"\n",
    "key_nucleus_consistent = \"DAPI_consistent\"\n",
    "\n",
    "merfish_zarr_path = \"/Users/alice/Documents/data/Cell_Segmentation/test_mouse_ileum.zarr\" # MODIFY PATH\n",
    "sdata = sd.read_zarr(merfish_zarr_path)\n",
    "\n",
    "sdata, _ = compute_consistent_cell(\n",
    "    sdata=sdata,\n",
    "    key_shape_nuclei_seg=key_nuclei_segmentation,\n",
    "    key_shape_cell_seg=key_cell_segmentation,\n",
    "    key_cell_consistent=key_cell_consistent,\n",
    "    key_nuclei_consistent=key_nucleus_consistent,\n",
    "    image_key=\"staining_z3\",\n",
    "    threshold_intersection_contain=0.95,\n",
    "    threshold_intersection_intersect= 1,\n",
    "    accepted_nb_nuclei_per_cell=None,\n",
    "    max_cell_nb_intersecting_nuclei=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9ebdb1",
   "metadata": {},
   "source": [
    "## Step 3: Training RNA2seg\n",
    "\n",
    "Now, we will train RNA2seg using the target segmentation created in Step 2.  \n",
    "\n",
    "### Initialize a RNAsegDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68afe78c9f9e67da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'vmunet'\n",
      "VMUnet not loaded\n",
      "100%|██████████| 64/64 [00:01<00:00, 43.16it/s]\n",
      "Number of valid patches: 48\n",
      "100%|██████████| 64/64 [00:01<00:00, 39.21it/s]\n",
      "compute density threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:06<00:00,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute density threshold: 6.498080s\n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from rna2seg.models import RNA2seg\n",
    "\n",
    "transform_resize  = A.Compose([\n",
    " A.Resize(width=512, height=512, interpolation=cv2.INTER_NEAREST),\n",
    "])\n",
    "\n",
    "dataset = RNA2segDataset(\n",
    "   sdata=sdata,\n",
    "   channels_dapi= [\"DAPI\"],\n",
    "   channels_cellbound=[\"Cellbound1\"],\n",
    "   shape_patch_key=f\"sopa_patches_rna2seg_{patch_width}_{patch_overlap}\", # Created at step 1\n",
    "   key_cell_consistent=key_cell_consistent, # Created at step 2\n",
    "   key_nucleus_consistent=key_nucleus_consistent, # Created at step 2\n",
    "   key_nuclei_segmentation=key_nuclei_segmentation,\n",
    "   gene_column=\"gene\",\n",
    "   density_threshold = None,\n",
    "   kernel_size_background_density = 10 ,\n",
    "   kernel_size_rna2img = 0.5,\n",
    "   max_filter_size_rna2img = 2,\n",
    "   transform_resize = transform_resize,\n",
    "   training_mode = True,\n",
    "   patch_dir = folder_patch_rna2seg,\n",
    "   patch_width=1200,\n",
    "   patch_overlap=50,\n",
    "   use_cache = True, \n",
    ")\n",
    "\n",
    "print((len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "238e86c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['img_cellbound', 'dapi', 'rna_img', 'mask_flow', 'mask_gradient', 'idx', 'patch_index', 'bounds', 'segmentation_nuclei'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b3cfdf",
   "metadata": {},
   "source": [
    "### Train / Validataion split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f02bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "train_indices, val_indices = train_test_split(\n",
    "    range(len(dataset)), test_size=0.1, shuffle=True, random_state=42\n",
    ")\n",
    "train_sampler = SubsetRandomSampler(train_indices) \n",
    "valid_sampler = SubsetRandomSampler(val_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec226eab",
   "metadata": {},
   "source": [
    "### Initialize Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "441fd505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(training_loader) 22\n",
      "len(training_loader) 3\n"
     ]
    }
   ],
   "source": [
    "training_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                              batch_size=2,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers = 0,\n",
    "                                              sampler=train_sampler,\n",
    "                                              collate_fn = custom_collate_fn,\n",
    "                                              )\n",
    "\n",
    "print( f\"len(training_loader) {len(training_loader)}\")\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                                batch_size=2,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers = 0,\n",
    "                                                sampler=valid_sampler,\n",
    "                                                collate_fn = custom_collate_fn,\n",
    "                                                )\n",
    "\n",
    "print( f\"len(training_loader) {len(validation_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500719ae4a3014d6",
   "metadata": {},
   "source": [
    "### Initilize RNA2seg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ca6ce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5da486ed8094a36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initiaisation of CPnet\n",
      "Initiaisation of ChannelInvariantNet\n"
     ]
    }
   ],
   "source": [
    "rnaseg = RNA2seg(\n",
    "    device,\n",
    "    net='unet',\n",
    "    flow_threshold = 0.9,\n",
    "    cellbound_flow_threshold = 0.4,\n",
    "    pretrained_model = None,\n",
    ")\n",
    "rnaseg = rnaseg.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(rnaseg.parameters(), lr=0.001, weight_decay=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c96e56",
   "metadata": {},
   "source": [
    "### Training RNA2seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "646fc91640fc8f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  validation loss: 4.0795408089955645\n",
      "best_val_loss: 4.0795408089955645\n",
      "  validation loss: 3.9352603753407798\n",
      "best_val_loss: 3.9352603753407798\n",
      "  validation loss: 4.032752990722656\n",
      "  validation loss: 3.6595205465952554\n",
      "best_val_loss: 3.6595205465952554\n",
      "training: 100%|██████████| 22/22 [01:26<00:00,  3.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [01:26<02:53, 86.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  validation loss: 5.133564313252767\n",
      "best_val_loss: 5.133564313252767\n",
      "  validation loss: 4.012377103169759\n",
      "best_val_loss: 4.012377103169759\n",
      "  validation loss: 3.7041075229644775\n",
      "best_val_loss: 3.7041075229644775\n",
      "  validation loss: 4.0180362065633135\n",
      "training: 100%|██████████| 22/22 [01:26<00:00,  3.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [02:52<01:26, 86.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  validation loss: 4.1740842660268145\n",
      "best_val_loss: 4.1740842660268145\n",
      "  validation loss: 3.9927518367767334\n",
      "best_val_loss: 3.9927518367767334\n",
      "  validation loss: 3.5406501293182373\n",
      "best_val_loss: 3.5406501293182373\n",
      "  validation loss: 3.28145170211792\n",
      "best_val_loss: 3.28145170211792\n",
      "training: 100%|██████████| 22/22 [01:26<00:00,  3.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [04:19<00:00, 86.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from rna2seg.train import train_one_epoch\n",
    "\n",
    "best_val_loss = np.inf\n",
    "path_save_model  = \"/Users/alice/Documents/data/Cell_Segmentation/test_mouse_ileum\"\n",
    "\n",
    "for epoch_index in tqdm(range(3)):\n",
    "\n",
    "    train_one_epoch(\n",
    "        device=device,\n",
    "        epoch_index=epoch_index,\n",
    "        rnaseg=rnaseg,\n",
    "        training_loader=training_loader,\n",
    "        optimizer=optimizer,\n",
    "        print_loss_every = int(len(training_loader) /3),\n",
    "        tb_writer= None,\n",
    "        validation_loader=validation_loader,\n",
    "        path_save_model=path_save_model,\n",
    "        cellbound_prob= 0.8,\n",
    "        best_val_loss=best_val_loss\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rna2seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
