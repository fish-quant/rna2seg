{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45c85f94c95b5ccf",
   "metadata": {},
   "source": [
    "# Objective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c645b82d3b2173fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T14:44:29.532122Z",
     "start_time": "2025-02-06T14:44:22.498902Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda3/envs/RNAseg/lib/python3.10/site-packages/dask/dataframe/__init__.py:31: FutureWarning: The legacy Dask DataFrame implementation is deprecated and will be removed in a future version. Set the configuration option `dataframe.query-planning` to `True` or None to enable the new Dask Dataframe implementation and silence this warning.\n",
      "  warnings.warn(\n",
      "/home/tom/anaconda3/envs/RNAseg/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/tom/anaconda3/envs/RNAseg/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/tom/anaconda3/envs/RNAseg/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'vmunet'\n",
      "VMUnet not loaded\n"
     ]
    }
   ],
   "source": [
    "import spatialdata as sd\n",
    "from pathlib import Path\n",
    "from rna_seg.dataset_zarr.patches import create_patch_rnaseg\n",
    "from rna_seg.dataset_zarr.RNAsegDataset import RNAsegDataset, custom_collate_fn\n",
    "from rna_seg.models import RNASeg\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from tqdm import tqdm\n",
    "from rna_seg.train import train_one_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d958b7bbf928bf",
   "metadata": {},
   "source": [
    "### step 1 create training dataset from zarr files\n",
    "* create crops shape \n",
    "* create folder of csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60be0f9817553592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T13:28:17.140897Z",
     "start_time": "2025-01-15T13:28:17.023449Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda3/envs/RNAseg/lib/python3.10/site-packages/spatialdata/_core/_elements.py:96: UserWarning: Key `sopa_patches_rna_seg_1200_50` already exists. Overwriting it in-memory.\n",
      "  self._check_key(key, self.keys(), self._shared_keys)\n",
      "\u001B[36;20m[INFO] (sopa.patches.patches)\u001B[0m 64 patches were saved in sdata['sopa_patches_rna_seg_1200_50']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 19.08 ss\n",
      "SpatialData object, with associated Zarr store: /media/tom/Transcend/open_merfish/test_spatial_data/from_cluster/test_mouse_ileum.zarr\n",
      "├── Images\n",
      "│     └── 'staining_z3': DataTree[cyx] (5, 9000, 9000), (5, 4500, 4500), (5, 2250, 2250), (5, 1125, 1125), (5, 562, 562)\n",
      "├── Points\n",
      "│     └── 'transcripts': DataFrame with shape: (<Delayed>, 9) (2D points)\n",
      "└── Shapes\n",
      "      ├── 'Cellbound1': GeoDataFrame shape: (3258, 1) (2D shapes)\n",
      "      ├── 'Cellbound1_consistent_with_nuclei': GeoDataFrame shape: (1007, 1) (2D shapes)\n",
      "      ├── 'Cellbound1_consistent_without_nuclei': GeoDataFrame shape: (2239, 1) (2D shapes)\n",
      "      ├── 'DAPI': GeoDataFrame shape: (2377, 1) (2D shapes)\n",
      "      ├── 'DAPI_consistent_in_cell': GeoDataFrame shape: (1007, 1) (2D shapes)\n",
      "      ├── 'DAPI_consistent_not_in_cell': GeoDataFrame shape: (1370, 1) (2D shapes)\n",
      "      ├── 'sopa_patches_rna_seg_1200_50': GeoDataFrame shape: (64, 3) (2D shapes)\n",
      "      └── 'sopa_patches_rna_seg_1200_150': GeoDataFrame shape: (81, 3) (2D shapes)\n",
      "with coordinate systems:\n",
      "    ▸ '_staining_z3_intrinsic', with elements:\n",
      "        staining_z3 (Images)\n",
      "    ▸ 'microns', with elements:\n",
      "        staining_z3 (Images), transcripts (Points), Cellbound1 (Shapes), Cellbound1_consistent_with_nuclei (Shapes), Cellbound1_consistent_without_nuclei (Shapes), DAPI (Shapes), DAPI_consistent_in_cell (Shapes), DAPI_consistent_not_in_cell (Shapes), sopa_patches_rna_seg_1200_50 (Shapes), sopa_patches_rna_seg_1200_150 (Shapes)\n"
     ]
    }
   ],
   "source": [
    "### load sdata and set path parameters \n",
    "merfish_zarr_path = \"/media/tom/Transcend/open_merfish/test_spatial_data/from_cluster/test_mouse_ileum.zarr\"\n",
    "sdata = sd.read_zarr(merfish_zarr_path)\n",
    "image_key = \"staining_z3\"\n",
    "patch_width = 1200\n",
    "patch_overlap = 50\n",
    "points_key = \"transcripts\"\n",
    "min_transcripts_per_patch = 0\n",
    "folder_patch_rna_seg = Path(merfish_zarr_path) / \".rna_seg\"\n",
    "\n",
    "### create patch in the sdata and precompute transcipt.csv for each patch with sopa\n",
    "create_patch_rnaseg(sdata,\n",
    "                    image_key=image_key,\n",
    "                    points_key=points_key,\n",
    "                    patch_width=patch_width,\n",
    "                    patch_overlap=patch_overlap,\n",
    "                    min_transcripts_per_patch=min_transcripts_per_patch,\n",
    "                    overwrite = True)\n",
    "print(sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b20b65d-d4b1-429d-9d8b-942dd52fc882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpatialData object, with associated Zarr store: /media/tom/Transcend/open_merfish/test_spatial_data/from_cluster/test_mouse_ileum.zarr\n",
       "├── Images\n",
       "│     └── 'staining_z3': DataTree[cyx] (5, 9000, 9000), (5, 4500, 4500), (5, 2250, 2250), (5, 1125, 1125), (5, 562, 562)\n",
       "├── Points\n",
       "│     └── 'transcripts': DataFrame with shape: (<Delayed>, 9) (2D points)\n",
       "└── Shapes\n",
       "      ├── 'Cellbound1': GeoDataFrame shape: (3258, 1) (2D shapes)\n",
       "      ├── 'Cellbound1_consistent_with_nuclei': GeoDataFrame shape: (1007, 1) (2D shapes)\n",
       "      ├── 'Cellbound1_consistent_without_nuclei': GeoDataFrame shape: (2239, 1) (2D shapes)\n",
       "      ├── 'DAPI': GeoDataFrame shape: (2377, 1) (2D shapes)\n",
       "      ├── 'DAPI_consistent_in_cell': GeoDataFrame shape: (1007, 1) (2D shapes)\n",
       "      ├── 'DAPI_consistent_not_in_cell': GeoDataFrame shape: (1370, 1) (2D shapes)\n",
       "      ├── 'sopa_patches_rna_seg_1200_50': GeoDataFrame shape: (64, 3) (2D shapes)\n",
       "      └── 'sopa_patches_rna_seg_1200_150': GeoDataFrame shape: (81, 3) (2D shapes)\n",
       "with coordinate systems:\n",
       "    ▸ '_staining_z3_intrinsic', with elements:\n",
       "        staining_z3 (Images)\n",
       "    ▸ 'microns', with elements:\n",
       "        staining_z3 (Images), transcripts (Points), Cellbound1 (Shapes), Cellbound1_consistent_with_nuclei (Shapes), Cellbound1_consistent_without_nuclei (Shapes), DAPI (Shapes), DAPI_consistent_in_cell (Shapes), DAPI_consistent_not_in_cell (Shapes), sopa_patches_rna_seg_1200_50 (Shapes), sopa_patches_rna_seg_1200_150 (Shapes)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f5cac439b7149",
   "metadata": {},
   "source": [
    "### Step 2 create training dataset from sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68afe78c9f9e67da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:03<00:00, 18.66it/s]\n",
      "Number of valid patches: 48\n"
     ]
    }
   ],
   "source": [
    "\n",
    "key_shape_cell_seg = \"Cellbound1\"\n",
    "key_nuclei_segmentation=\"DAPI\"\n",
    "# to name for future shape that will be created in the sdata\n",
    "key_cell_consistent = \"Cellbound1_consistent\"\n",
    "key_nucleus_consistent = \"DAPI_consistent\"\n",
    "\n",
    "transform_resize  = A.Compose([\n",
    " A.Resize(width=512, height=512, interpolation=cv2.INTER_NEAREST),\n",
    "])\n",
    "\n",
    "\n",
    "dataset = RNAsegDataset(\n",
    " sdata=sdata,\n",
    " channels_dapi= [\"DAPI\"],\n",
    " channels_cellbound=[\"Cellbound1\"],\n",
    "\n",
    " shape_patch_key=\"sopa_patches_rna_seg_1200_50\",\n",
    "\n",
    " key_cell_consistent=key_cell_consistent,\n",
    "    key_nucleus_consistent=key_nucleus_consistent,\n",
    " key_nuclei_segmentation=key_nuclei_segmentation,\n",
    " gene_column=\"gene\",\n",
    " density_threshold = None,\n",
    " kernel_size_background_density = 10 ,\n",
    " kernel_size_rna2img = 0.5,\n",
    " max_filter_size_rna2img = 2,\n",
    " transform_resize = transform_resize,\n",
    "    training_mode = True,\n",
    "    path_cache = folder_patch_rna_seg,\n",
    "     patch_width=1200,\n",
    "     patch_overlap=50,\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3460dfc9b7f9f13a",
   "metadata": {},
   "source": [
    "### set threshold on density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e17bd83bd725bcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:02<00:00, 23.85it/s]\n",
      "compute density threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:08<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute density threshold: 8.630728s\n",
      "Error while loading cache: [Errno 2] No such file or directory: '/media/tom/Transcend/open_merfish/test_spatial_data/from_cluster/test_mouse_ileum.zarr/.rna_seg/0/img_cellbound.tif'\n",
      "Recomputing the patch 0\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'remove_cell_in_background' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m dataset\u001B[38;5;241m.\u001B[39mset_threshold( max_nb_crops\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m500\u001B[39m,\n\u001B[1;32m      2\u001B[0m               kernel_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m9\u001B[39m,\n\u001B[1;32m      3\u001B[0m               percentile_threshold \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m,\n\u001B[1;32m      4\u001B[0m               shape\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m1200\u001B[39m, \u001B[38;5;241m1200\u001B[39m),)\n\u001B[0;32m----> 5\u001B[0m \u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mkeys()\n",
      "File \u001B[0;32m~/Bureau/phd/rna_seg2paper/rna_seg_pkg/rna_seg/dataset_zarr/RNAsegDataset.py:581\u001B[0m, in \u001B[0;36m__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    577\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRecomputing the patch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpatch_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    580\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m compute_all_patch:\n\u001B[0;32m--> 581\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpath_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    582\u001B[0m         folder_to_save \u001B[38;5;241m=\u001B[39m Path(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpath_cache) \u001B[38;5;241m/\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpatch_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    583\u001B[0m         folder_to_save\u001B[38;5;241m.\u001B[39mmkdir(exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, parents\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Bureau/phd/rna_seg2paper/rna_seg_pkg/rna_seg/dataset_zarr/RNAsegDataset.py:750\u001B[0m, in \u001B[0;36m_get_patch_input\u001B[0;34m(self, patch_index, folder_to_save)\u001B[0m\n\u001B[1;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m segmentation_nuclei \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    749\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m (segmentation_nuclei\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], segmentation_nuclei\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m!=\u001B[39m (target_width, target_height):\n\u001B[0;32m--> 750\u001B[0m             segmentation_nuclei \u001B[38;5;241m=\u001B[39m pad_image2D_to_shape(segmentation_nuclei, target_shape\u001B[38;5;241m=\u001B[39m(target_width, target_height))\n\u001B[1;32m    753\u001B[0m     (mask_gradient, agreement_segmentation, background,\n\u001B[1;32m    754\u001B[0m      remove_cell_in_background)\u001B[38;5;241m=\u001B[39mremove_cell_in_background(\n\u001B[1;32m    755\u001B[0m         agreement_segmentation\u001B[38;5;241m=\u001B[39magreement_segmentation,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    762\u001B[0m \n\u001B[1;32m    763\u001B[0m     )\n\u001B[1;32m    764\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mUnboundLocalError\u001B[0m: local variable 'remove_cell_in_background' referenced before assignment"
     ]
    }
   ],
   "source": [
    "dataset.set_threshold( max_nb_crops=500,\n",
    "              kernel_size = 9,\n",
    "              percentile_threshold = 5,\n",
    "              shape=(1200, 1200),)\n",
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500719ae4a3014d6",
   "metadata": {},
   "source": [
    "# Step 3: Initilize and RNAseg Model, optinally load pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da486ed8094a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\"\n",
    "\n",
    "rnaseg = RNASeg(device,\n",
    "                net='unet',\n",
    "                flow_threshold = 0.9,\n",
    "                cellbound_flow_threshold = 0.4,\n",
    "                pretrained_model = None,\n",
    "                )\n",
    "rnaseg.to(device)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20daa7f378cc94fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48601ec4e057d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = 0.1\n",
    "indices = list(range(len(dataset)))\n",
    "split = int(np.floor(validation_split * len(dataset)))\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_indices) # does it change the order at each iteration?\n",
    "valid_sampler = SubsetRandomSampler(val_indices) # does it change the order at each iteration?\n",
    "\n",
    "\n",
    "#dataset.reloaded = False\n",
    "training_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                              batch_size=2,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers = 5,\n",
    "                                              sampler=train_sampler,\n",
    "                                              collate_fn = custom_collate_fn,\n",
    "                                              )\n",
    "\n",
    "print( f\"len(training_loader) {len(training_loader)}\")\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                                batch_size=2,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers =  3,\n",
    "                                                sampler=valid_sampler,\n",
    "                                                collate_fn = custom_collate_fn,\n",
    "                                                )\n",
    "\n",
    "optimizer = torch.optim.AdamW(rnaseg.parameters(),\n",
    "                              lr=0.001,\n",
    "                              weight_decay=0.01)\n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a205dd6f204be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "646fc91640fc8f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[Abatch 0  0%|          | 0/22 [00:00<?, ?it/s]\n",
      "  batch nb 1 loss: 1.2506969996861048 \n",
      "batch 0\n",
      "batch 1\n",
      "  validation loss: 6.478799104690552\n",
      "best_val_loss: 6.478799104690552\n",
      "\n",
      "\u001B[Abatch 1  5%|▍         | 1/22 [00:11<04:03, 11.61s/it]\n",
      "\n",
      "\u001B[Abatch 2  9%|▉         | 2/22 [00:20<03:22, 10.11s/it]\n",
      "\n",
      "\u001B[Abatch 3 14%|█▎        | 3/22 [00:26<02:36,  8.25s/it]\n",
      "\n",
      "\u001B[Abatch 4 18%|█▊        | 4/22 [00:32<02:10,  7.25s/it]\n",
      "\n",
      "\u001B[Abatch 5 23%|██▎       | 5/22 [00:38<01:57,  6.90s/it]\n",
      "\n",
      "\u001B[Abatch 6 27%|██▋       | 6/22 [00:44<01:44,  6.52s/it]\n",
      "\n",
      "\u001B[Abatch 7 32%|███▏      | 7/22 [00:49<01:31,  6.07s/it]\n",
      "  batch nb 8 loss: 8.296125854764666 \n",
      "batch 0\n",
      "batch 1\n",
      "  validation loss: 5.849609136581421\n",
      "best_val_loss: 5.849609136581421\n",
      "\n",
      "\u001B[Abatch 8 36%|███▋      | 8/22 [00:58<01:39,  7.11s/it]\n",
      "\n",
      "\u001B[Abatch 9 41%|████      | 9/22 [01:04<01:27,  6.69s/it]\n",
      "\n",
      "\u001B[Abatch 1045%|████▌     | 10/22 [01:10<01:15,  6.30s/it]\n",
      "\n",
      "\u001B[Abatch 1150%|█████     | 11/22 [01:15<01:05,  5.94s/it]\n",
      "\n",
      "\u001B[Abatch 1255%|█████▍    | 12/22 [01:20<00:56,  5.65s/it]\n",
      "\n",
      "\u001B[Abatch 1359%|█████▉    | 13/22 [01:25<00:48,  5.44s/it]\n",
      "\n",
      "\u001B[Abatch 1464%|██████▎   | 14/22 [01:30<00:42,  5.32s/it]\n",
      "  batch nb 15 loss: 7.296939304896763 \n",
      "batch 0\n",
      "batch 1\n",
      "  validation loss: 5.01100754737854\n",
      "best_val_loss: 5.01100754737854\n",
      "\n",
      "\u001B[Abatch 1568%|██████▊   | 15/22 [01:39<00:45,  6.46s/it]\n",
      "\n",
      "\u001B[Abatch 1673%|███████▎  | 16/22 [01:44<00:36,  6.00s/it]\n",
      "\n",
      "\u001B[Abatch 1777%|███████▋  | 17/22 [01:49<00:28,  5.68s/it]\n",
      "\n",
      "\u001B[Abatch 1882%|████████▏ | 18/22 [01:54<00:21,  5.47s/it]\n",
      "\n",
      "\u001B[Abatch 1986%|████████▋ | 19/22 [01:59<00:15,  5.33s/it]\n",
      "\n",
      "\u001B[Abatch 2091%|█████████ | 20/22 [02:04<00:10,  5.22s/it]\n",
      "\n",
      "\u001B[Abatch 2195%|█████████▌| 21/22 [02:09<00:05,  5.14s/it]\n",
      "  batch nb 22 loss: 6.275889158248901 \n",
      "batch 0\n",
      "batch 1\n",
      "  validation loss: 5.031475305557251\n",
      "\n",
      "training: 100%|██████████| 22/22 [02:21<00:00,  6.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [02:21<04:43, 141.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[Abatch 0  0%|          | 0/22 [00:00<?, ?it/s]\n",
      "  batch nb 1 loss: 0.644050053187779 \n",
      "batch 0\n",
      "batch 1\n",
      "  validation loss: 4.956424713134766\n",
      "best_val_loss: 4.956424713134766\n",
      "\n",
      "\u001B[Abatch 1  5%|▍         | 1/22 [00:09<03:21,  9.60s/it]\n",
      "\n",
      "\u001B[Abatch 2  9%|▉         | 2/22 [00:14<02:19,  7.00s/it]\n",
      "\n",
      "\u001B[Abatch 3 14%|█▎        | 3/22 [00:20<02:00,  6.35s/it]\n",
      "\n",
      "\u001B[Abatch 4 18%|█▊        | 4/22 [00:25<01:44,  5.83s/it]\n",
      "\n",
      "\u001B[Abatch 5 23%|██▎       | 5/22 [00:30<01:35,  5.63s/it]\n",
      "\n",
      "\u001B[Abatch 6 27%|██▋       | 6/22 [00:36<01:29,  5.59s/it]\n",
      "\n",
      "\u001B[Abatch 7 32%|███▏      | 7/22 [00:41<01:21,  5.46s/it]\n",
      "  batch nb 8 loss: 6.86816109929766 \n",
      "batch 0\n",
      "batch 1\n",
      "  validation loss: 4.480439066886902\n",
      "best_val_loss: 4.480439066886902\n",
      "\n",
      "\u001B[Abatch 8 36%|███▋      | 8/22 [00:51<01:35,  6.85s/it]\n",
      "\n",
      "\u001B[Abatch 9 41%|████      | 9/22 [00:56<01:23,  6.45s/it]\n",
      "\n",
      "\u001B[Abatch 1045%|████▌     | 10/22 [01:01<01:12,  6.00s/it]\n",
      "\n",
      "\u001B[Abatch 1150%|█████     | 11/22 [01:06<01:03,  5.75s/it]\n",
      "\n",
      "\u001B[Abatch 1255%|█████▍    | 12/22 [01:12<00:55,  5.55s/it]\n",
      "\n",
      "\u001B[Abatch 1359%|█████▉    | 13/22 [01:17<00:48,  5.42s/it]\n",
      "\n",
      "\u001B[Abatch 1464%|██████▎   | 14/22 [01:22<00:42,  5.32s/it]\n",
      "  batch nb 15 loss: 5.53181529045105 \n",
      "batch 0\n",
      "batch 1\n",
      "  validation loss: 4.11455225944519\n",
      "best_val_loss: 4.11455225944519\n",
      "\n",
      "\u001B[Abatch 1568%|██████▊   | 15/22 [01:31<00:45,  6.56s/it]\n",
      "\n",
      "\u001B[Abatch 1673%|███████▎  | 16/22 [01:36<00:36,  6.14s/it]\n",
      "\n",
      "\u001B[Abatch 1777%|███████▋  | 17/22 [01:41<00:29,  5.84s/it]\n",
      "\n",
      "\u001B[Abatch 1882%|████████▏ | 18/22 [01:47<00:22,  5.63s/it]\n",
      "\n",
      "\u001B[Abatch 1986%|████████▋ | 19/22 [01:56<00:20,  6.72s/it]\n",
      "\n",
      "\u001B[Abatch 2091%|█████████ | 20/22 [02:02<00:13,  6.61s/it]\n",
      "\n",
      "\u001B[Abatch 2195%|█████████▌| 21/22 [02:08<00:06,  6.33s/it]\n",
      "  batch nb 22 loss: 5.510088307516916 \n",
      "batch 0\n",
      "batch 1\n",
      "  validation loss: 4.033479571342468\n",
      "best_val_loss: 4.033479571342468\n",
      "\n",
      "training: 100%|██████████| 22/22 [02:18<00:00,  6.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [04:40<02:19, 139.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[Abatch 0  0%|          | 0/22 [00:00<?, ?it/s]\n",
      "  batch nb 1 loss: 0.6761629240853446 \n",
      "batch 0\n",
      "batch 1\n",
      "  validation loss: 3.8062593936920166\n",
      "best_val_loss: 3.8062593936920166\n",
      "\n",
      "\u001B[Abatch 1  5%|▍         | 1/22 [00:10<03:34, 10.20s/it]\n",
      "\n",
      "\u001B[Abatch 2  9%|▉         | 2/22 [00:15<02:31,  7.57s/it]\n",
      "\n",
      "\u001B[Abatch 3 14%|█▎        | 3/22 [00:21<02:03,  6.48s/it]\n",
      "\n",
      "\u001B[Abatch 4 18%|█▊        | 4/22 [00:26<01:48,  6.05s/it]\n",
      "\n",
      "\u001B[Abatch 5 23%|██▎       | 5/22 [00:31<01:36,  5.70s/it]\n",
      "\n",
      "\u001B[Abatch 6 27%|██▋       | 6/22 [00:36<01:27,  5.48s/it]\n",
      "\n",
      "\u001B[Abatch 7 32%|███▏      | 7/22 [00:41<01:21,  5.43s/it]\n",
      "  batch nb 8 loss: 4.402904902185712 \n",
      "batch 0\n",
      "batch 1\n",
      "  validation loss: 3.7692790031433105\n",
      "best_val_loss: 3.7692790031433105\n",
      "\n",
      "\u001B[Abatch 8 36%|███▋      | 8/22 [00:51<01:34,  6.76s/it]\n",
      "\n",
      "\u001B[Abatch 9 41%|████      | 9/22 [00:57<01:22,  6.35s/it]\n",
      "\n",
      "\u001B[Abatch 1045%|████▌     | 10/22 [01:02<01:11,  5.95s/it]\n",
      "\n",
      "\u001B[Abatch 1150%|█████     | 11/22 [01:07<01:02,  5.66s/it]\n",
      "\n",
      "\u001B[Abatch 1255%|█████▍    | 12/22 [01:12<00:54,  5.44s/it]\n",
      "\n",
      "\u001B[Abatch 1359%|█████▉    | 13/22 [01:17<00:47,  5.31s/it]\n",
      "\n",
      "\u001B[Abatch 1464%|██████▎   | 14/22 [01:21<00:41,  5.20s/it]\n",
      "  batch nb 15 loss: 4.939064128058297 \n",
      "batch 0\n",
      "batch 1\n",
      "  validation loss: 3.3188979625701904\n",
      "best_val_loss: 3.3188979625701904\n",
      "\n",
      "\u001B[Abatch 1568%|██████▊   | 15/22 [01:32<00:47,  6.76s/it]\n",
      "\n",
      "\u001B[Abatch 1673%|███████▎  | 16/22 [01:37<00:38,  6.41s/it]\n",
      "\n",
      "\u001B[Abatch 1777%|███████▋  | 17/22 [01:42<00:29,  5.97s/it]\n",
      "\n",
      "\u001B[Abatch 1882%|████████▏ | 18/22 [01:47<00:22,  5.67s/it]\n",
      "\n",
      "\u001B[Abatch 1986%|████████▋ | 19/22 [01:52<00:16,  5.46s/it]\n",
      "\n",
      "\u001B[Abatch 2091%|█████████ | 20/22 [01:57<00:10,  5.32s/it]\n",
      "\n",
      "\u001B[Abatch 2195%|█████████▌| 21/22 [02:02<00:05,  5.22s/it]\n",
      "  batch nb 22 loss: 4.749943222318377 \n",
      "batch 0\n",
      "batch 1\n",
      "  validation loss: 2.8776239156723022\n",
      "best_val_loss: 2.8776239156723022\n",
      "\n",
      "training: 100%|██████████| 22/22 [02:13<00:00,  6.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [06:54<00:00, 138.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = np.inf\n",
    "path_save_model = \"/home/tom/toremove\"\n",
    "for epoch_index in tqdm(range(3)):\n",
    "\n",
    "    train_one_epoch(\n",
    "        device=device,\n",
    "    epoch_index=epoch_index,\n",
    "    rnaseg=rnaseg,\n",
    "    training_loader=training_loader,\n",
    "    optimizer=optimizer,\n",
    "    print_loss_every = int(len(training_loader) /3),\n",
    "    tb_writer= None,\n",
    "    validation_loader=validation_loader,\n",
    "    path_save_model=path_save_model,\n",
    "    cellbound_prob=  0.8,\n",
    "    best_val_loss=best_val_loss\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185fba37ed1da50a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f1c7f5-7973-4638-8efe-799da32098d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5096a5a-64d4-459d-950d-12a991afbaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
