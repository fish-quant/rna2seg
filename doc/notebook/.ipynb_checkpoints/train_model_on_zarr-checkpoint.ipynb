{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45c85f94c95b5ccf",
   "metadata": {},
   "source": [
    "# Objective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c645b82d3b2173fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T13:27:19.040571Z",
     "start_time": "2025-01-15T13:27:16.493050Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda3/envs/RNAseg/lib/python3.10/site-packages/dask/dataframe/__init__.py:31: FutureWarning: The legacy Dask DataFrame implementation is deprecated and will be removed in a future version. Set the configuration option `dataframe.query-planning` to `True` or None to enable the new Dask Dataframe implementation and silence this warning.\n",
      "  warnings.warn(\n",
      "/home/tom/anaconda3/envs/RNAseg/lib/python3.10/site-packages/anndata/utils.py:429: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/tom/anaconda3/envs/RNAseg/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/tom/anaconda3/envs/RNAseg/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'vmunet'\n",
      "VMUnet not loaded\n"
     ]
    }
   ],
   "source": [
    "import spatialdata as sd\n",
    "from pathlib import Path\n",
    "from rna_seg.dataset_zarr.patches import create_patch_rnaseg\n",
    "from rna_seg.dataset_zarr.RNA2segDataset import RNA2segDataset, custom_collate_fn\n",
    "from rna_seg.models import RNASeg\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from tqdm import tqdm\n",
    "from rna_seg.train import train_one_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d958b7bbf928bf",
   "metadata": {},
   "source": [
    "### step 1 create training dataset from zarr files\n",
    "* create crops shape \n",
    "* create folder of csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60be0f9817553592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T13:28:17.140897Z",
     "start_time": "2025-01-15T13:28:17.023449Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda3/envs/RNAseg/lib/python3.10/site-packages/spatialdata/_core/_elements.py:96: UserWarning: Key `sopa_patches_rna_seg_1200_50` already exists. Overwriting it in-memory.\n",
      "  self._check_key(key, self.keys(), self._shared_keys)\n",
      "\u001b[36;20m[INFO] (sopa.patches.patches)\u001b[0m 64 patches were saved in sdata['sopa_patches_rna_seg_1200_50']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 20.12 ss\n",
      "SpatialData object, with associated Zarr store: /media/tom/Transcend/open_merfish/test_spatial_data/from_cluster/test_mouse_ileum.zarr\n",
      "├── Images\n",
      "│     └── 'staining_z3': DataTree[cyx] (5, 9000, 9000), (5, 4500, 4500), (5, 2250, 2250), (5, 1125, 1125), (5, 562, 562)\n",
      "├── Points\n",
      "│     └── 'transcripts': DataFrame with shape: (<Delayed>, 9) (2D points)\n",
      "└── Shapes\n",
      "      ├── 'Cellbound1': GeoDataFrame shape: (3258, 1) (2D shapes)\n",
      "      ├── 'Cellbound1_consistent_with_nuclei': GeoDataFrame shape: (1007, 1) (2D shapes)\n",
      "      ├── 'Cellbound1_consistent_without_nuclei': GeoDataFrame shape: (2239, 1) (2D shapes)\n",
      "      ├── 'DAPI': GeoDataFrame shape: (2377, 1) (2D shapes)\n",
      "      ├── 'DAPI_consistent_in_cell': GeoDataFrame shape: (1007, 1) (2D shapes)\n",
      "      ├── 'DAPI_consistent_not_in_cell': GeoDataFrame shape: (1370, 1) (2D shapes)\n",
      "      └── 'sopa_patches_rna_seg_1200_50': GeoDataFrame shape: (64, 3) (2D shapes)\n",
      "with coordinate systems:\n",
      "    ▸ '_staining_z3_intrinsic', with elements:\n",
      "        staining_z3 (Images)\n",
      "    ▸ 'microns', with elements:\n",
      "        staining_z3 (Images), transcripts (Points), Cellbound1 (Shapes), Cellbound1_consistent_with_nuclei (Shapes), Cellbound1_consistent_without_nuclei (Shapes), DAPI (Shapes), DAPI_consistent_in_cell (Shapes), DAPI_consistent_not_in_cell (Shapes), sopa_patches_rna_seg_1200_50 (Shapes)\n"
     ]
    }
   ],
   "source": [
    "### load sdata and set path parameters \n",
    "merfish_zarr_path = \"/media/tom/Transcend/open_merfish/test_spatial_data/from_cluster/test_mouse_ileum.zarr\"\n",
    "sdata = sd.read_zarr(merfish_zarr_path)\n",
    "image_key = \"staining_z3\"\n",
    "patch_width = 1200\n",
    "patch_overlap = 50\n",
    "points_key = \"transcripts\"\n",
    "min_transcripts_per_patch = 0\n",
    "folder_patch_rna_seg = Path(merfish_zarr_path) / \".rna_seg\"\n",
    "\n",
    "### create patch in the sdata and precompute transcipt.csv for each patch with sopa\n",
    "create_patch_rnaseg(sdata,\n",
    "                    image_key=image_key,\n",
    "                    points_key=points_key,\n",
    "                    patch_width=patch_width,\n",
    "                    patch_overlap=patch_overlap,\n",
    "                    min_transcripts_per_patch=min_transcripts_per_patch,\n",
    "                    overwrite = True)\n",
    "print(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f5cac439b7149",
   "metadata": {},
   "source": [
    "### Step 2 create training dataset from sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac416ce-0c1f-45da-a34d-9a1bb3d67b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68afe78c9f9e67da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 34.58it/s]\n",
      "Number of valid patches: 48\n"
     ]
    }
   ],
   "source": [
    "\n",
    "key_shape_cell_seg = \"Cellbound1\"\n",
    "key_nuclei_segmentation=\"DAPI\"\n",
    "# to name for future shape that will be created in the sdata\n",
    "key_cell_consistent = \"Cellbound1_consistent\"\n",
    "key_nucleus_consistent = \"DAPI_consistent\"\n",
    "\n",
    "transform_resize  = A.Compose([\n",
    " A.Resize(width=512, height=512, interpolation=cv2.INTER_NEAREST),\n",
    "])\n",
    "\n",
    "\n",
    "dataset = RNA2segDataset(\n",
    " sdata=sdata,\n",
    " channels_dapi= [\"DAPI\"],\n",
    " channels_cellbound=[\"Cellbound1\"],\n",
    "\n",
    " shape_patch_key=\"sopa_patches_rna_seg_1200_50\",\n",
    "\n",
    " key_cell_consistent=key_cell_consistent,\n",
    "    key_nucleus_consistent=key_nucleus_consistent,\n",
    " key_nuclei_segmentation=key_nuclei_segmentation,\n",
    " gene_column=\"gene\",\n",
    " density_threshold = None,\n",
    " kernel_size_background_density = 10 ,\n",
    " kernel_size_rna2img = 0.5,\n",
    " max_filter_size_rna2img = 2,\n",
    " transform_resize = transform_resize,\n",
    "    training_mode = True,\n",
    "    path_cache = sdata.path / f'.rnaseg'\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3460dfc9b7f9f13a",
   "metadata": {},
   "source": [
    "### set threshold on density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17bd83bd725bcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:01<00:00, 34.66it/s]\n",
      "compute density threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 26/48 [00:04<00:03,  6.03it/s]"
     ]
    }
   ],
   "source": [
    "dataset.set_threshold( max_nb_crops=500,\n",
    "              kernel_size = 9,\n",
    "              percentile_threshold = 5,\n",
    "              shape=(1200, 1200),)\n",
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500719ae4a3014d6",
   "metadata": {},
   "source": [
    "# Step 3: Initilize and RNAseg Model, optinally load pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da486ed8094a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\"\n",
    "\n",
    "rnaseg = RNASeg(device,\n",
    "                net='unet',\n",
    "                flow_threshold = 0.9,\n",
    "                cellbound_flow_threshold = 0.4,\n",
    "                pretrained_model = None,\n",
    "                )\n",
    "rnaseg.to(device)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20daa7f378cc94fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48601ec4e057d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = 0.1\n",
    "indices = list(range(len(dataset)))\n",
    "split = int(np.floor(validation_split * len(dataset)))\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_indices) # does it change the order at each iteration?\n",
    "valid_sampler = SubsetRandomSampler(val_indices) # does it change the order at each iteration?\n",
    "\n",
    "\n",
    "#dataset.reloaded = False\n",
    "training_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                              batch_size=5,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers = 5,\n",
    "                                              sampler=train_sampler,\n",
    "                                              collate_fn = custom_collate_fn,\n",
    "                                              )\n",
    "\n",
    "print( f\"len(training_loader) {len(training_loader)}\")\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                                batch_size=2,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers =  3,\n",
    "                                                sampler=valid_sampler,\n",
    "                                                collate_fn = custom_collate_fn,\n",
    "                                                )\n",
    "\n",
    "optimizer = torch.optim.AdamW(rnaseg.parameters(),\n",
    "                              lr=0.001,\n",
    "                              weight_decay=0.01)\n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a205dd6f204be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646fc91640fc8f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = np.inf\n",
    "path_save_model = \"/home/tom/toremove\"\n",
    "for epoch_index in tqdm(range(3)):\n",
    "\n",
    "    train_one_epoch(\n",
    "        device=device,\n",
    "    epoch_index=epoch_index,\n",
    "    rnaseg=rnaseg,\n",
    "    training_loader=training_loader,\n",
    "    optimizer=optimizer,\n",
    "    print_loss_every = int(len(training_loader) /3),\n",
    "    tb_writer= None,\n",
    "    validation_loader=validation_loader,\n",
    "    path_save_model=path_save_model,\n",
    "    cellbound_prob=  0.8,\n",
    "    best_val_loss=best_val_loss\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185fba37ed1da50a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f1c7f5-7973-4638-8efe-799da32098d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5096a5a-64d4-459d-950d-12a991afbaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
